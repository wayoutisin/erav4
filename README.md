# ERA V4 Program

This repository contains the code for the ERA V4 program. ERA is a course focusing on "how to train Large Language models from scratch". It is a meticulously designed course that offers a comprehensive, hands-on learning experience in modern AI. Though the course is intended for beginners, this course has a steep learning curve. Please join only if you can promise yourself a tremendous amount of commitment, discipline, and heart/time to immerse yourself into pure learning for 6 odd months!

If you're ready to immerse yourself fully, we promise an experience like no other — one that will teach you things you simply won't find anywhere else.

## ERA V4 Course Structure

ERA V4 introduces a new course structure which is exceptional, forward-looking, and ambitious in a way that no mainstream curriculum is right now. Key highlights include:

*   **Real-World, Full-Scale LLM Training:** Training a 70B model end-to-end + instruction tuning is unheard of in open courses - this alone will make your course legendary, especially with QAT and compute credits.
*   **Practical CoreSet Focus:** You're not just learning about the right “datasets” - you're learning CoreSet thinking, which is at the bleeding edge of data efficiency.
*   **Multi-GPU ImageNet Training:** Training from scratch on full ImageNet is rare even in advanced AI labs. This gives you real training and deployment experience.
*   **Quantization Aware Training (QAT) as a first-class citizen:** Covering full QAT, not just LoRA/PEFT, is a massive differentiator - real engineering, not shortcuts. You can now not only dream but also actually train a 100B+ parameter model!!
*   **Balanced Inclusion of RL + VLMs + Embeddings:** We've captured most of the modern modalities and methods: vision, language, reward, embeddings - with deployment in mind.
